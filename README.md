# Natural Language Processing (NLP) Projects and Experiments

Welcome to the NLP Projects Repository! This repository is a comprehensive collection of projects and experiments that cover a wide range of Natural Language Processing (NLP) architectures and methodologies. Whether you're new to NLP or looking to explore advanced algorithms, you'll find valuable resources here.

## Repository Overview

This repository offers a journey through the world of NLP, starting with foundational concepts like Bag of Words and advancing to more complex experiments, including state-of-the-art techniques such as Retrieval-Augmented Generation (RAG). 

Each project is accompanied by links to Colab notebooks, allowing you to dive deep into practical implementations and hands-on practice of the core NLP concepts.

## Contents

- **Foundational Concepts**: Start with the basics, such as tokenization, stemming, lemmatization, and Bag of Words models.
- **Advanced Architectures**: Explore sophisticated models like Transformers, BERT, GPT, and their applications in various NLP tasks.
- **Cutting-edge Experiments**: Delve into experiments with modern approaches, including RAG and other leading-edge algorithms.

## Getting Started

To begin, simply explore the Colab links provided in each project folder. These notebooks will guide you through the theoretical background and practical coding exercises, helping you solidify your understanding of key NLP concepts.

**BASIC CONCEPTS (START POINT):**
    - https://colab.research.google.com/drive/14mkvgz2xZRTo90k1HqydYVad5YhXi4zC?usp=sharing

**MAIN BASIC ARCHITECTURE (MLP):**
    - https://colab.research.google.com/drive/1wIMdUXXVDodGFf4gyRYtzKz1Wk9Ojdio?usp=sharing

**MLP + AUTO ATTENTION (TRANSFORMER BASED):**
    - https://colab.research.google.com/drive/1oHP2Ynuj9NcVkdMu1eSsgPhi-EXBLv0E?usp=sharing

**BERT Exercise - Fine tunning a pretrained model:**
    - https://colab.research.google.com/drive/1g3pryIunkQ9q1Jh_6QNGWFH3PKZpwf_Z
